{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4YKzHHfmHXA"
      },
      "source": [
        "# **Згорткові Нейронні Мережі (ЗНМ) або Convolutional Neural Networks (CNN)**\n",
        "\n",
        "**Застосування**\n",
        "\n",
        "![image](https://www.mdpi.com/electronics/electronics-10-02470/article_deploy/html/images/electronics-10-02470-g013.png)\n",
        "\n",
        "![image](https://miro.medium.com/v2/resize:fit:1024/1*9roDC1WM2DwwQMyzzuIcFg.jpeg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoutdaZDP9lW"
      },
      "source": [
        "# **Fully Connected Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhitAgTemzeE",
        "outputId": "bd1c39b5-2461-4853-e94c-fc431b26728f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "steps_per_epoch 195\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "num_classes = 10\n",
        "num_features = np.product(x_train.shape[1:])  # 32x32 image with RGB channels\n",
        "\n",
        "learning_rate = 0.0001\n",
        "batch_size = 256\n",
        "\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "print(\"steps_per_epoch\", steps_per_epoch)\n",
        "\n",
        "# Convert integer pixels to float32\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "# Flatten 32x32x3 matrices into 3072-element vectors\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "\n",
        "# Shuffle training data\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIE921XzkHtA",
        "outputId": "f99cf5f4-8bf5-4464-a2b2-3616c6a07fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               1573376   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, InputLayer\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(num_features,)),  # Flatten the input vector\n",
        "    Dense(512, activation='relu'),  #\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),  # Added another layer\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),  # Added another layer\n",
        "    Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=50, verbose=1)\n",
        "\n",
        "callbacks = [lr_scheduler]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "cXVmfNGwkHnm",
        "outputId": "66df3407-0dd5-463c-a8b1-9eb3e42b6732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Visualize the model architecture\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egn2TLeykHhI",
        "outputId": "8d8fa6f5-59c0-49d4-e33a-5654ee373cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - 3s 9ms/step - loss: 2.0128 - accuracy: 0.2671 - val_loss: 1.8126 - val_accuracy: 0.3627 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.8121 - accuracy: 0.3527 - val_loss: 1.7011 - val_accuracy: 0.3995 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.7315 - accuracy: 0.3841 - val_loss: 1.6430 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.6807 - accuracy: 0.4021 - val_loss: 1.5967 - val_accuracy: 0.4374 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.6438 - accuracy: 0.4152 - val_loss: 1.5989 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6075 - accuracy: 0.4288 - val_loss: 1.5317 - val_accuracy: 0.4601 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5710 - accuracy: 0.4433 - val_loss: 1.5188 - val_accuracy: 0.4664 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.5501 - accuracy: 0.4497 - val_loss: 1.4937 - val_accuracy: 0.4681 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.5265 - accuracy: 0.4600 - val_loss: 1.5251 - val_accuracy: 0.4570 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5048 - accuracy: 0.4676 - val_loss: 1.4556 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4860 - accuracy: 0.4711 - val_loss: 1.4481 - val_accuracy: 0.4879 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.4628 - accuracy: 0.4845 - val_loss: 1.4417 - val_accuracy: 0.4863 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4500 - accuracy: 0.4847 - val_loss: 1.4171 - val_accuracy: 0.4938 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.4275 - accuracy: 0.4947 - val_loss: 1.4099 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4205 - accuracy: 0.4976 - val_loss: 1.3955 - val_accuracy: 0.5045 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4005 - accuracy: 0.5052 - val_loss: 1.3849 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3882 - accuracy: 0.5077 - val_loss: 1.3741 - val_accuracy: 0.5106 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3794 - accuracy: 0.5123 - val_loss: 1.3810 - val_accuracy: 0.5084 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.3625 - accuracy: 0.5186 - val_loss: 1.3595 - val_accuracy: 0.5223 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.3459 - accuracy: 0.5236 - val_loss: 1.3600 - val_accuracy: 0.5196 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 1.3361 - accuracy: 0.5269 - val_loss: 1.3567 - val_accuracy: 0.5161 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.3209 - accuracy: 0.5318 - val_loss: 1.3389 - val_accuracy: 0.5256 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 1.3115 - accuracy: 0.5352 - val_loss: 1.3377 - val_accuracy: 0.5291 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.3008 - accuracy: 0.5372 - val_loss: 1.3291 - val_accuracy: 0.5296 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2922 - accuracy: 0.5407 - val_loss: 1.3195 - val_accuracy: 0.5314 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2758 - accuracy: 0.5473 - val_loss: 1.3138 - val_accuracy: 0.5359 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2702 - accuracy: 0.5502 - val_loss: 1.3221 - val_accuracy: 0.5311 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2553 - accuracy: 0.5545 - val_loss: 1.3127 - val_accuracy: 0.5337 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.2508 - accuracy: 0.5546 - val_loss: 1.3078 - val_accuracy: 0.5375 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.2413 - accuracy: 0.5585 - val_loss: 1.3078 - val_accuracy: 0.5362 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.2297 - accuracy: 0.5639 - val_loss: 1.3024 - val_accuracy: 0.5358 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.2155 - accuracy: 0.5680 - val_loss: 1.3020 - val_accuracy: 0.5439 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 1.2136 - accuracy: 0.5699 - val_loss: 1.2900 - val_accuracy: 0.5440 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 1.1979 - accuracy: 0.5756 - val_loss: 1.2912 - val_accuracy: 0.5448 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.1910 - accuracy: 0.5778 - val_loss: 1.2824 - val_accuracy: 0.5466 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1829 - accuracy: 0.5800 - val_loss: 1.2883 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1815 - accuracy: 0.5802 - val_loss: 1.2785 - val_accuracy: 0.5523 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1656 - accuracy: 0.5858 - val_loss: 1.2845 - val_accuracy: 0.5481 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 1.1594 - accuracy: 0.5891 - val_loss: 1.2713 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.1577 - accuracy: 0.5890 - val_loss: 1.2815 - val_accuracy: 0.5461 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 1.1393 - accuracy: 0.5965 - val_loss: 1.2999 - val_accuracy: 0.5420 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1313 - accuracy: 0.5983 - val_loss: 1.2708 - val_accuracy: 0.5515 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1258 - accuracy: 0.5989 - val_loss: 1.2696 - val_accuracy: 0.5544 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1157 - accuracy: 0.6025 - val_loss: 1.2694 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1076 - accuracy: 0.6046 - val_loss: 1.2663 - val_accuracy: 0.5535 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1031 - accuracy: 0.6101 - val_loss: 1.2847 - val_accuracy: 0.5484 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0995 - accuracy: 0.6108 - val_loss: 1.2821 - val_accuracy: 0.5561 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0894 - accuracy: 0.6128 - val_loss: 1.2580 - val_accuracy: 0.5599 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.0778 - accuracy: 0.6179 - val_loss: 1.2660 - val_accuracy: 0.5558 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0737 - accuracy: 0.6167 - val_loss: 1.2689 - val_accuracy: 0.5565 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0617 - accuracy: 0.6211 - val_loss: 1.2833 - val_accuracy: 0.5478 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.0521 - accuracy: 0.6246 - val_loss: 1.2785 - val_accuracy: 0.5566 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.0556 - accuracy: 0.6243 - val_loss: 1.2685 - val_accuracy: 0.5593 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0499 - accuracy: 0.6271 - val_loss: 1.2576 - val_accuracy: 0.5552 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0332 - accuracy: 0.6306 - val_loss: 1.2833 - val_accuracy: 0.5540 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0321 - accuracy: 0.6316 - val_loss: 1.2739 - val_accuracy: 0.5553 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0203 - accuracy: 0.6365 - val_loss: 1.2666 - val_accuracy: 0.5568 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 1.0152 - accuracy: 0.6357 - val_loss: 1.2801 - val_accuracy: 0.5450 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0062 - accuracy: 0.6394 - val_loss: 1.3042 - val_accuracy: 0.5502 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0014 - accuracy: 0.6422 - val_loss: 1.2761 - val_accuracy: 0.5575 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0015 - accuracy: 0.6411 - val_loss: 1.2718 - val_accuracy: 0.5654 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.9884 - accuracy: 0.6481 - val_loss: 1.2721 - val_accuracy: 0.5559 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9845 - accuracy: 0.6491 - val_loss: 1.2845 - val_accuracy: 0.5565 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9780 - accuracy: 0.6503 - val_loss: 1.2766 - val_accuracy: 0.5608 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9719 - accuracy: 0.6532 - val_loss: 1.2706 - val_accuracy: 0.5668 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9643 - accuracy: 0.6584 - val_loss: 1.2709 - val_accuracy: 0.5592 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.9642 - accuracy: 0.6539 - val_loss: 1.2646 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9526 - accuracy: 0.6610 - val_loss: 1.2734 - val_accuracy: 0.5632 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.9473 - accuracy: 0.6627 - val_loss: 1.2729 - val_accuracy: 0.5638 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.9392 - accuracy: 0.6632 - val_loss: 1.2713 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.9311 - accuracy: 0.6684 - val_loss: 1.2722 - val_accuracy: 0.5629 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.9282 - accuracy: 0.6681 - val_loss: 1.2857 - val_accuracy: 0.5650 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9239 - accuracy: 0.6704 - val_loss: 1.2811 - val_accuracy: 0.5622 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9160 - accuracy: 0.6725 - val_loss: 1.2895 - val_accuracy: 0.5558 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9164 - accuracy: 0.6729 - val_loss: 1.2903 - val_accuracy: 0.5551 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9074 - accuracy: 0.6774 - val_loss: 1.2882 - val_accuracy: 0.5602 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.8965 - accuracy: 0.6790 - val_loss: 1.2897 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.8909 - accuracy: 0.6810 - val_loss: 1.2882 - val_accuracy: 0.5598 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.8941 - accuracy: 0.6797 - val_loss: 1.2916 - val_accuracy: 0.5617 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8953 - accuracy: 0.6780 - val_loss: 1.2937 - val_accuracy: 0.5605 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.8796 - accuracy: 0.6859 - val_loss: 1.2871 - val_accuracy: 0.5634 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8701 - accuracy: 0.6875 - val_loss: 1.2949 - val_accuracy: 0.5615 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8692 - accuracy: 0.6901 - val_loss: 1.2950 - val_accuracy: 0.5616 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8574 - accuracy: 0.6932 - val_loss: 1.2908 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8507 - accuracy: 0.6955 - val_loss: 1.3090 - val_accuracy: 0.5614 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8557 - accuracy: 0.6918 - val_loss: 1.2955 - val_accuracy: 0.5650 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8427 - accuracy: 0.6990 - val_loss: 1.3029 - val_accuracy: 0.5641 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.8418 - accuracy: 0.6979 - val_loss: 1.3005 - val_accuracy: 0.5640 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.8342 - accuracy: 0.7014 - val_loss: 1.3140 - val_accuracy: 0.5599 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8374 - accuracy: 0.7010 - val_loss: 1.3135 - val_accuracy: 0.5618 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8298 - accuracy: 0.7046 - val_loss: 1.3156 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.8177 - accuracy: 0.7071 - val_loss: 1.3137 - val_accuracy: 0.5655 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8086 - accuracy: 0.7101 - val_loss: 1.3184 - val_accuracy: 0.5593 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8117 - accuracy: 0.7101 - val_loss: 1.3232 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8089 - accuracy: 0.7099 - val_loss: 1.3316 - val_accuracy: 0.5580 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8016 - accuracy: 0.7136 - val_loss: 1.3190 - val_accuracy: 0.5628 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7989 - accuracy: 0.7146 - val_loss: 1.3297 - val_accuracy: 0.5570 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7946 - accuracy: 0.7152 - val_loss: 1.3435 - val_accuracy: 0.5622 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7843 - accuracy: 0.7197 - val_loss: 1.3324 - val_accuracy: 0.5621 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7796 - accuracy: 0.7213 - val_loss: 1.3351 - val_accuracy: 0.5661 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_data,\n",
        "                    epochs=100,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVKMl4kIQDcU"
      },
      "source": [
        "# **Згорткова Нейронна Мережа (Convolutional Neural Network)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tbyvOItRvNG",
        "outputId": "78498734-d995-492a-924c-fc60c12ab638"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 3072), (50000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld64gd-rrC4d",
        "outputId": "e7d40dd7-299a-47b2-bdfc-a31a2ff0d78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "steps_per_epoch 195\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Input\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Reshape the data to include the channel dimension (1 for grayscale images)\n",
        "x_train = x_train.reshape((-1, 32, 32, 3)).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape((-1, 32, 32, 3)).astype(\"float32\") / 255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "print(\"steps_per_epoch\", steps_per_epoch)\n",
        "\n",
        "# Створення об'єкту Dataset для тренувальних даних (ознаки та цільова змінна)\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "\n",
        "batch_size = 512 # Формування пакетів розміром 512\n",
        "# Налаштування обробки тренувального набору даних\n",
        "dataset_train = (dataset_train\n",
        "                 .repeat()  # Повторення даних для кількості епох\n",
        "                 .shuffle(1024)  # Випадкове перетасовування з буфером розміром 1024\n",
        "                 .batch(batch_size)  # Формування пакетів розміром 512\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)  # Завантаження наступного пакету в пам'ять\n",
        "                 )\n",
        "\n",
        "# Створення об'єкту Dataset для тестових даних (ознаки та цільова змінна)\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Conv2D(filters=64, kernel_size=(5, 5), kernel_initializer=initializer, activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=128, kernel_size=(5, 5), kernel_initializer=initializer, activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5, seed=0),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(1024, kernel_initializer=initializer, activation=\"relu\"),\n",
        "    Dropout(0.5, seed=0),\n",
        "    Dense(10, kernel_initializer=initializer, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu_RCADmSG_a",
        "outputId": "4ec2a403-04d0-477f-bb26-d333470d6280"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 64)        4864      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 10, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              3277824   \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,497,866\n",
            "Trainable params: 3,497,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NNA0KMFkkHcE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dhntGVrkHXV",
        "outputId": "5d1cde0e-e4d6-4d78-cfe6-31ff93da70cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5749 - accuracy: 0.4253\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55760, saving model to best_model.h5\n",
            "195/195 [==============================] - 9s 36ms/step - loss: 1.5735 - accuracy: 0.4258 - val_loss: 1.2408 - val_accuracy: 0.5576 - lr: 0.0010\n",
            "Epoch 2/2\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2026 - accuracy: 0.5742\n",
            "Epoch 2: val_accuracy improved from 0.55760 to 0.63780, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.2026 - accuracy: 0.5742 - val_loss: 1.0308 - val_accuracy: 0.6378 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(dataset_train,\n",
        "                    epochs=2,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=dataset_test,\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_AZdKIkGsI",
        "outputId": "a1fea4a3-f455-4c49-bfa1-3eb9a1624d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 11ms/step - loss: 1.1341 - accuracy: 0.5963\n",
            "Test accuracy: 59.63%\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(dataset_test)\n",
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTswa9N-QLF7"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "scAsyT2HJQnU"
      },
      "outputs": [],
      "source": [
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gq-qdvskkGnJ"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, label):\n",
        "    # Define the augmentation pipeline\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        A.CoarseDropout(max_holes=8, max_height=4, max_width=4, fill_value=0, p=0.5),  # Similar to Random Erasing\n",
        "        A.RandomContrast(limit=0.2, p=0.5),\n",
        "        A.RandomBrightness(limit=0.2, p=0.5),\n",
        "        A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, p=0.5)  # Another form of Random Erasing\n",
        "    ])\n",
        "\n",
        "    # Apply the augmentations\n",
        "    augmented_image = transform(image=image.numpy())['image']\n",
        "    return augmented_image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hGd8v-WVkGh4"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (train_dataset\n",
        "                 .shuffle(buffer_size=1024)\n",
        "                 .batch(batch_size)\n",
        "                 .map(lambda x, y: tf.py_function(augment_image, [x, y], [tf.float32, tf.int64]),\n",
        "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHKW9_bLkGZg",
        "outputId": "1f5f9264-7a0f-47d6-aecd-b6750b89b955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 64)        4864      \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 10, 10, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 5, 5, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1024)              3277824   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,497,866\n",
            "Trainable params: 3,497,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=128, kernel_size=(5, 5), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(1024, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et_wBJV_kF5h",
        "outputId": "5c683d2f-a7c2-45f7-8150-38c88f28ccb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 0.4495\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56240, saving model to best_model.h5\n",
            "195/195 [==============================] - 8s 34ms/step - loss: 1.5239 - accuracy: 0.4495 - val_loss: 1.2224 - val_accuracy: 0.5624 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1517 - accuracy: 0.5924\n",
            "Epoch 2: val_accuracy improved from 0.56240 to 0.64040, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 36ms/step - loss: 1.1517 - accuracy: 0.5924 - val_loss: 1.0162 - val_accuracy: 0.6404 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9997 - accuracy: 0.6484\n",
            "Epoch 3: val_accuracy improved from 0.64040 to 0.68040, saving model to best_model.h5\n",
            "195/195 [==============================] - 8s 42ms/step - loss: 0.9997 - accuracy: 0.6484 - val_loss: 0.9282 - val_accuracy: 0.6804 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.6854\n",
            "Epoch 4: val_accuracy improved from 0.68040 to 0.69890, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 0.8954 - accuracy: 0.6854 - val_loss: 0.8683 - val_accuracy: 0.6989 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8265 - accuracy: 0.7112\n",
            "Epoch 5: val_accuracy improved from 0.69890 to 0.71920, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.8265 - accuracy: 0.7112 - val_loss: 0.8044 - val_accuracy: 0.7192 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7594 - accuracy: 0.7338\n",
            "Epoch 6: val_accuracy improved from 0.71920 to 0.72480, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.7594 - accuracy: 0.7338 - val_loss: 0.7892 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.7517\n",
            "Epoch 7: val_accuracy improved from 0.72480 to 0.74390, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.7075 - accuracy: 0.7517 - val_loss: 0.7411 - val_accuracy: 0.7439 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7688\n",
            "Epoch 8: val_accuracy improved from 0.74390 to 0.74690, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.6602 - accuracy: 0.7688 - val_loss: 0.7274 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.7859\n",
            "Epoch 9: val_accuracy improved from 0.74690 to 0.76230, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6104 - accuracy: 0.7859 - val_loss: 0.6962 - val_accuracy: 0.7623 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.8003\n",
            "Epoch 10: val_accuracy improved from 0.76230 to 0.76530, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5663 - accuracy: 0.8003 - val_loss: 0.6899 - val_accuracy: 0.7653 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.8117\n",
            "Epoch 11: val_accuracy did not improve from 0.76530\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5342 - accuracy: 0.8117 - val_loss: 0.6923 - val_accuracy: 0.7639 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8268\n",
            "Epoch 12: val_accuracy improved from 0.76530 to 0.77040, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4916 - accuracy: 0.8268 - val_loss: 0.6908 - val_accuracy: 0.7704 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8369\n",
            "Epoch 13: val_accuracy improved from 0.77040 to 0.77690, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4657 - accuracy: 0.8369 - val_loss: 0.6609 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.8420\n",
            "Epoch 14: val_accuracy improved from 0.77690 to 0.77800, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4475 - accuracy: 0.8420 - val_loss: 0.6643 - val_accuracy: 0.7780 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8517\n",
            "Epoch 15: val_accuracy did not improve from 0.77800\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4197 - accuracy: 0.8517 - val_loss: 0.6710 - val_accuracy: 0.7744 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8599\n",
            "Epoch 16: val_accuracy did not improve from 0.77800\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3938 - accuracy: 0.8599 - val_loss: 0.6749 - val_accuracy: 0.7753 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8654\n",
            "Epoch 17: val_accuracy did not improve from 0.77800\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3823 - accuracy: 0.8654 - val_loss: 0.6771 - val_accuracy: 0.7768 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.8709\n",
            "Epoch 18: val_accuracy improved from 0.77800 to 0.78010, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 0.3666 - accuracy: 0.8709 - val_loss: 0.6683 - val_accuracy: 0.7801 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8772\n",
            "Epoch 19: val_accuracy did not improve from 0.78010\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3485 - accuracy: 0.8772 - val_loss: 0.6750 - val_accuracy: 0.7740 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8820\n",
            "Epoch 20: val_accuracy improved from 0.78010 to 0.78260, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.3325 - accuracy: 0.8820 - val_loss: 0.6692 - val_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.8871\n",
            "Epoch 21: val_accuracy did not improve from 0.78260\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.3178 - accuracy: 0.8871 - val_loss: 0.6758 - val_accuracy: 0.7819 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.8914\n",
            "Epoch 22: val_accuracy did not improve from 0.78260\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3085 - accuracy: 0.8914 - val_loss: 0.6812 - val_accuracy: 0.7814 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8952\n",
            "Epoch 23: val_accuracy did not improve from 0.78260\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.2972 - accuracy: 0.8952 - val_loss: 0.6874 - val_accuracy: 0.7785 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8974\n",
            "Epoch 24: val_accuracy improved from 0.78260 to 0.78540, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2896 - accuracy: 0.8974 - val_loss: 0.6742 - val_accuracy: 0.7854 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.8998\n",
            "Epoch 25: val_accuracy did not improve from 0.78540\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.2869 - accuracy: 0.8998 - val_loss: 0.6843 - val_accuracy: 0.7821 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9015\n",
            "Epoch 26: val_accuracy did not improve from 0.78540\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 0.2789 - accuracy: 0.9015 - val_loss: 0.6887 - val_accuracy: 0.7806 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.9053\n",
            "Epoch 27: val_accuracy improved from 0.78540 to 0.78700, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.2670 - accuracy: 0.9053 - val_loss: 0.6757 - val_accuracy: 0.7870 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9073\n",
            "Epoch 28: val_accuracy did not improve from 0.78700\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.2635 - accuracy: 0.9073 - val_loss: 0.7046 - val_accuracy: 0.7843 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9095\n",
            "Epoch 29: val_accuracy did not improve from 0.78700\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2574 - accuracy: 0.9095 - val_loss: 0.6852 - val_accuracy: 0.7843 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9122\n",
            "Epoch 30: val_accuracy did not improve from 0.78700\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2508 - accuracy: 0.9122 - val_loss: 0.6916 - val_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9115\n",
            "Epoch 31: val_accuracy did not improve from 0.78700\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.2509 - accuracy: 0.9115 - val_loss: 0.7278 - val_accuracy: 0.7787 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9162\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.78700\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2406 - accuracy: 0.9162 - val_loss: 0.6945 - val_accuracy: 0.7823 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9277\n",
            "Epoch 33: val_accuracy improved from 0.78700 to 0.79280, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 0.2067 - accuracy: 0.9277 - val_loss: 0.6782 - val_accuracy: 0.7928 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9324\n",
            "Epoch 34: val_accuracy did not improve from 0.79280\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.1917 - accuracy: 0.9324 - val_loss: 0.6881 - val_accuracy: 0.7928 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9352\n",
            "Epoch 35: val_accuracy did not improve from 0.79280\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.1865 - accuracy: 0.9352 - val_loss: 0.6985 - val_accuracy: 0.7892 - lr: 5.0000e-04\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9360\n",
            "Epoch 36: val_accuracy did not improve from 0.79280\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1822 - accuracy: 0.9360 - val_loss: 0.6972 - val_accuracy: 0.7914 - lr: 5.0000e-04\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9374\n",
            "Epoch 37: val_accuracy did not improve from 0.79280\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1792 - accuracy: 0.9374 - val_loss: 0.6944 - val_accuracy: 0.7899 - lr: 5.0000e-04\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9375\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.79280\n",
            "195/195 [==============================] - 7s 36ms/step - loss: 0.1770 - accuracy: 0.9375 - val_loss: 0.7251 - val_accuracy: 0.7909 - lr: 5.0000e-04\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9447\n",
            "Epoch 39: val_accuracy improved from 0.79280 to 0.79650, saving model to best_model.h5\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.1582 - accuracy: 0.9447 - val_loss: 0.6889 - val_accuracy: 0.7965 - lr: 2.5000e-04\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9455\n",
            "Epoch 40: val_accuracy improved from 0.79650 to 0.79770, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 0.1578 - accuracy: 0.9455 - val_loss: 0.6797 - val_accuracy: 0.7977 - lr: 2.5000e-04\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9473\n",
            "Epoch 41: val_accuracy did not improve from 0.79770\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.1511 - accuracy: 0.9473 - val_loss: 0.6843 - val_accuracy: 0.7968 - lr: 2.5000e-04\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9489\n",
            "Epoch 42: val_accuracy improved from 0.79770 to 0.79940, saving model to best_model.h5\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1451 - accuracy: 0.9489 - val_loss: 0.6832 - val_accuracy: 0.7994 - lr: 2.5000e-04\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9501\n",
            "Epoch 43: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 36ms/step - loss: 0.1437 - accuracy: 0.9501 - val_loss: 0.6939 - val_accuracy: 0.7979 - lr: 2.5000e-04\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9513\n",
            "Epoch 44: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 37ms/step - loss: 0.1409 - accuracy: 0.9513 - val_loss: 0.6832 - val_accuracy: 0.7986 - lr: 2.5000e-04\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9498\n",
            "Epoch 45: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 37ms/step - loss: 0.1433 - accuracy: 0.9498 - val_loss: 0.6890 - val_accuracy: 0.7969 - lr: 2.5000e-04\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9521\n",
            "Epoch 46: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.1374 - accuracy: 0.9521 - val_loss: 0.6952 - val_accuracy: 0.7986 - lr: 2.5000e-04\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9508\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1403 - accuracy: 0.9508 - val_loss: 0.6930 - val_accuracy: 0.7941 - lr: 2.5000e-04\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9547\n",
            "Epoch 48: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1301 - accuracy: 0.9547 - val_loss: 0.6976 - val_accuracy: 0.7976 - lr: 1.2500e-04\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.9546\n",
            "Epoch 49: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1306 - accuracy: 0.9546 - val_loss: 0.6932 - val_accuracy: 0.7985 - lr: 1.2500e-04\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9559\n",
            "Epoch 50: val_accuracy did not improve from 0.79940\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.1259 - accuracy: 0.9559 - val_loss: 0.6961 - val_accuracy: 0.7992 - lr: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(dataset_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=dataset_test,\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n6sdPVxJpNY",
        "outputId": "d6dc0b2f-94c6-45c8-e7a6-cb5e939afdb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 14ms/step - loss: 0.6961 - accuracy: 0.7992\n",
            "Test accuracy: 79.92%\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(dataset_test)\n",
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6I-GN9QPIN"
      },
      "source": [
        "# **Transfer Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH3Jz8phaAut"
      },
      "source": [
        "## **MobileNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "fzcVkm1vaAP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "MfHKbQcFPUQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCBGV0GNPUbP",
        "outputId": "235d9521-4155-4135-ed65-fb91336bf9de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_epoch 195\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# x_train = np.repeat(x_train[..., np.newaxis], 3, -1)\n",
        "# x_test = np.repeat(x_test[..., np.newaxis], 3, -1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "print(\"steps_per_epoch\", steps_per_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JghDtog3XTjb"
      },
      "outputs": [],
      "source": [
        "def resize_image(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    return image, label\n",
        "\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset_train = (dataset_train\n",
        "                 .repeat()\n",
        "                 .map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                 .shuffle(buffer_size=1024)\n",
        "                 .batch(batch_size)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "dataset_test = (dataset_test.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                .batch(batch_size)\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KbjtZO_PUmb",
        "outputId": "d5b2de5e-6000-4022-d3a6-d91adfa811b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsSMLRxLa5ox",
        "outputId": "7c20d127-12e9-4da0-c4cd-76f1710925ac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_224\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_11[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                    )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)              )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                          )                                ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwi27ZtaPUwn",
        "outputId": "3baf47c3-0eb1-4ac7-f4e1-004b086a7dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9319 - accuracy: 0.6885\n",
            "Epoch 1: val_accuracy improved from -inf to 0.76710, saving model to best_model.h5\n",
            "195/195 [==============================] - 89s 414ms/step - loss: 0.9319 - accuracy: 0.6885 - val_loss: 0.6724 - val_accuracy: 0.7671 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7920\n",
            "Epoch 2: val_accuracy improved from 0.76710 to 0.78960, saving model to best_model.h5\n",
            "195/195 [==============================] - 74s 378ms/step - loss: 0.6088 - accuracy: 0.7920 - val_loss: 0.6006 - val_accuracy: 0.7896 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.8108\n",
            "Epoch 3: val_accuracy improved from 0.78960 to 0.80050, saving model to best_model.h5\n",
            "195/195 [==============================] - 75s 384ms/step - loss: 0.5525 - accuracy: 0.8108 - val_loss: 0.5670 - val_accuracy: 0.8005 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8180\n",
            "Epoch 4: val_accuracy improved from 0.80050 to 0.80570, saving model to best_model.h5\n",
            "195/195 [==============================] - 76s 390ms/step - loss: 0.5253 - accuracy: 0.8180 - val_loss: 0.5547 - val_accuracy: 0.8057 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.8256\n",
            "Epoch 5: val_accuracy improved from 0.80570 to 0.81120, saving model to best_model.h5\n",
            "195/195 [==============================] - 74s 382ms/step - loss: 0.5030 - accuracy: 0.8256 - val_loss: 0.5468 - val_accuracy: 0.8112 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(dataset_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=dataset_test,\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF0OtbutZ70q"
      },
      "source": [
        "## **Adding Dense 1024**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQFSLmvlPU7W",
        "outputId": "a0f121ca-d557-4b27-a01d-260885a96b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,579,978\n",
            "Trainable params: 1,321,994\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN2auaVRPVFg",
        "outputId": "ddd53796-160e-4a30-bef5-376ea579b757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.7289\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79670, saving model to best_model.h5\n",
            "195/195 [==============================] - 76s 365ms/step - loss: 0.8169 - accuracy: 0.7289 - val_loss: 0.5756 - val_accuracy: 0.7967 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5889 - accuracy: 0.7951\n",
            "Epoch 2: val_accuracy improved from 0.79670 to 0.80540, saving model to best_model.h5\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.5889 - accuracy: 0.7951 - val_loss: 0.5499 - val_accuracy: 0.8054 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.8086\n",
            "Epoch 3: val_accuracy did not improve from 0.80540\n",
            "195/195 [==============================] - 69s 356ms/step - loss: 0.5434 - accuracy: 0.8086 - val_loss: 0.5430 - val_accuracy: 0.8047 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8220\n",
            "Epoch 4: val_accuracy improved from 0.80540 to 0.82120, saving model to best_model.h5\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.5057 - accuracy: 0.8220 - val_loss: 0.5119 - val_accuracy: 0.8212 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.8316\n",
            "Epoch 5: val_accuracy improved from 0.82120 to 0.82750, saving model to best_model.h5\n",
            "195/195 [==============================] - 70s 361ms/step - loss: 0.4787 - accuracy: 0.8316 - val_loss: 0.4927 - val_accuracy: 0.8275 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8385\n",
            "Epoch 6: val_accuracy did not improve from 0.82750\n",
            "195/195 [==============================] - 70s 358ms/step - loss: 0.4572 - accuracy: 0.8385 - val_loss: 0.5021 - val_accuracy: 0.8233 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8474\n",
            "Epoch 7: val_accuracy improved from 0.82750 to 0.83040, saving model to best_model.h5\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.4350 - accuracy: 0.8474 - val_loss: 0.4912 - val_accuracy: 0.8304 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8514\n",
            "Epoch 8: val_accuracy improved from 0.83040 to 0.83260, saving model to best_model.h5\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.4228 - accuracy: 0.8514 - val_loss: 0.4869 - val_accuracy: 0.8326 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8555\n",
            "Epoch 9: val_accuracy did not improve from 0.83260\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.4012 - accuracy: 0.8555 - val_loss: 0.4942 - val_accuracy: 0.8298 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8642\n",
            "Epoch 10: val_accuracy did not improve from 0.83260\n",
            "195/195 [==============================] - 70s 360ms/step - loss: 0.3849 - accuracy: 0.8642 - val_loss: 0.4903 - val_accuracy: 0.8319 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(dataset_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=dataset_test,\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D04R3kC_aOtG"
      },
      "source": [
        "## **Trainable MobileNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-xqu8kznciM",
        "outputId": "bb66cab8-9b0e-40de-80f4-1c5289d34566"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_224\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_12[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                    )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)              )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                          )                                ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 2,223,872\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyp9SuG1PVPU",
        "outputId": "901224bd-1713-428e-b878-ea5ce9820da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,579,978\n",
            "Trainable params: 2,041,994\n",
            "Non-trainable params: 1,537,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "base_model.trainable = True\n",
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == \"block_16_project\":\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBvtNRlIPVZt",
        "outputId": "696ed6bd-5aba-4d4e-c439-98e1fcac9585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.7746\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49960, saving model to best_model.h5\n",
            "195/195 [==============================] - 79s 382ms/step - loss: 0.6530 - accuracy: 0.7746 - val_loss: 4.1577 - val_accuracy: 0.4996 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.8283\n",
            "Epoch 2: val_accuracy improved from 0.49960 to 0.53530, saving model to best_model.h5\n",
            "195/195 [==============================] - 104s 532ms/step - loss: 0.4969 - accuracy: 0.8283 - val_loss: 3.4275 - val_accuracy: 0.5353 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8425\n",
            "Epoch 3: val_accuracy improved from 0.53530 to 0.59280, saving model to best_model.h5\n",
            "195/195 [==============================] - 106s 543ms/step - loss: 0.4456 - accuracy: 0.8425 - val_loss: 2.9224 - val_accuracy: 0.5928 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8591\n",
            "Epoch 4: val_accuracy improved from 0.59280 to 0.59920, saving model to best_model.h5\n",
            "195/195 [==============================] - 108s 555ms/step - loss: 0.4024 - accuracy: 0.8591 - val_loss: 2.6619 - val_accuracy: 0.5992 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8695\n",
            "Epoch 5: val_accuracy improved from 0.59920 to 0.65600, saving model to best_model.h5\n",
            "195/195 [==============================] - 114s 587ms/step - loss: 0.3727 - accuracy: 0.8695 - val_loss: 2.5862 - val_accuracy: 0.6560 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.8770\n",
            "Epoch 6: val_accuracy did not improve from 0.65600\n",
            "195/195 [==============================] - 107s 550ms/step - loss: 0.3445 - accuracy: 0.8770 - val_loss: 3.3940 - val_accuracy: 0.6148 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.8859\n",
            "Epoch 7: val_accuracy did not improve from 0.65600\n",
            "195/195 [==============================] - 106s 544ms/step - loss: 0.3185 - accuracy: 0.8859 - val_loss: 3.1102 - val_accuracy: 0.5846 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.8930\n",
            "Epoch 8: val_accuracy did not improve from 0.65600\n",
            "195/195 [==============================] - 106s 544ms/step - loss: 0.3000 - accuracy: 0.8930 - val_loss: 3.4563 - val_accuracy: 0.5488 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.8997\n",
            "Epoch 9: val_accuracy did not improve from 0.65600\n",
            "195/195 [==============================] - 106s 543ms/step - loss: 0.2791 - accuracy: 0.8997 - val_loss: 2.4457 - val_accuracy: 0.6071 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9091\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.65600\n",
            "195/195 [==============================] - 106s 542ms/step - loss: 0.2563 - accuracy: 0.9091 - val_loss: 3.7560 - val_accuracy: 0.5250 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(dataset_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=dataset_test,\n",
        "                    callbacks=callbacks\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l77ZlIqdc6lP"
      },
      "source": [
        "## **One more transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMUO5Ig0c53G",
        "outputId": "665ed8f2-c4a3-4628-821d-cb33560b0f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "conv_base.trainable = False\n",
        "\n",
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtztguJHedTM",
        "outputId": "5de7ad2b-3995-4759-cff8-2939d8aaea9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FocbAAfWc2hK"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False\n",
        "# set_trainable = False\n",
        "# for layer in conv_base.layers:\n",
        "#     if layer.name == \"block5_conv1\":\n",
        "#         set_trainable = True\n",
        "#     if set_trainable:\n",
        "#         layer.trainable = True\n",
        "#     else:\n",
        "#         layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxIGKuzHc2Lz",
        "outputId": "9998afda-4d49-4140-8b56-4f93873d9336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,927,370\n",
            "Trainable params: 3,212,682\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "modified_model = models.Sequential([\n",
        "   conv_base,\n",
        "   layers.Flatten(),\n",
        "  #  layers.Dense(1024, activation=\"relu\"),\n",
        "   layers.Dense(128, activation=\"relu\"),\n",
        "   layers.Dropout(0.5),\n",
        "   layers.Dense(10, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "modified_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbOUxZq7aTIt",
        "outputId": "4ae1f5c3-342d-468d-a4e5-c941263f988a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_epoch 195\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# x_train = np.repeat(x_train[..., np.newaxis], 3, -1)\n",
        "# x_test = np.repeat(x_test[..., np.newaxis], 3, -1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "print(\"steps_per_epoch\", steps_per_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mVYQ30knet8v"
      },
      "outputs": [],
      "source": [
        "def resize_image(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    return image, label\n",
        "\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset_train = (dataset_train\n",
        "                 .repeat()\n",
        "                 .map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                 .shuffle(buffer_size=1024)\n",
        "                 .batch(batch_size)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "dataset_test = (dataset_test.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                .batch(batch_size)\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGYk3APhaS6H",
        "outputId": "1801b541-1d06-4fd9-9adf-3905c4940017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,927,370\n",
            "Trainable params: 3,212,682\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "\n",
        "# Early stopping and learning rate reduction on plateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
        "tf_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "tf_model = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "tf_tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "callbacks = [lr_scheduler, tf_stopping, tf_model, tf_tensorboard]\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "modified_model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "modified_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUrD6E8xJphO",
        "outputId": "ffaac2c9-83c9-4e0d-b745-58be7cb23ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1862 - accuracy: 0.1720\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33350, saving model to best_model.h5\n",
            "195/195 [==============================] - 287s 1s/step - loss: 2.1862 - accuracy: 0.1720 - val_loss: 1.9015 - val_accuracy: 0.3335 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0037 - accuracy: 0.2262\n",
            "Epoch 2: val_accuracy improved from 0.33350 to 0.45900, saving model to best_model.h5\n",
            "195/195 [==============================] - 254s 1s/step - loss: 2.0037 - accuracy: 0.2262 - val_loss: 1.7572 - val_accuracy: 0.4590 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9530 - accuracy: 0.2554\n",
            "Epoch 3: val_accuracy improved from 0.45900 to 0.49150, saving model to best_model.h5\n",
            "195/195 [==============================] - 258s 1s/step - loss: 1.9530 - accuracy: 0.2554 - val_loss: 1.7007 - val_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9275 - accuracy: 0.2623\n",
            "Epoch 4: val_accuracy did not improve from 0.49150\n",
            "195/195 [==============================] - 253s 1s/step - loss: 1.9275 - accuracy: 0.2623 - val_loss: 1.6355 - val_accuracy: 0.4904 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9136 - accuracy: 0.2674\n",
            "Epoch 5: val_accuracy did not improve from 0.49150\n",
            "195/195 [==============================] - 253s 1s/step - loss: 1.9136 - accuracy: 0.2674 - val_loss: 1.6405 - val_accuracy: 0.4833 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = modified_model.fit(dataset_train,\n",
        "                             epochs=5,\n",
        "                             batch_size=batch_size,\n",
        "                             steps_per_epoch=steps_per_epoch,\n",
        "                             validation_data=dataset_test,\n",
        "                             callbacks=callbacks\n",
        "                             )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JmxQ8vjfBO2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWF64NrWhOmT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}